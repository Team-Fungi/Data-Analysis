{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reDfqiI58oVq"
      },
      "source": [
        "# 1. Ambiguous nucleotides - removing sequencing errors\n",
        "- check if they are abundant in certain sequences (higher than 1% could be because of sequencing errors => not good to use)\n",
        "- check if there is a big los if we delete sequences with 1 or more ambiguous nucleotides\n",
        "- what if juste delete the ambiguous nucleotides in the sequences themselves but don't delete the entire sequence?\\\n",
        "If we are able to delete these without losing a lot of important data (distribution remains the same for example, not a big loss of indidvidual species), it would simplify the OHE and kmers a lot (because only ATGC instead of ATGCRYSWKMBDHVN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDhktwrROazO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuKL4QxJ8oIZ"
      },
      "outputs": [],
      "source": [
        "def how_many_ambi(dataframe):\n",
        "    df = pd.read_csv(dataframe)\n",
        "    searchfor = ['R', 'Y', 'S', 'W', 'K', 'M', 'B', 'D', 'H', 'V', 'N']\n",
        "    df['AMBI'] = df['SEQ'].str.count('|'.join(searchfor))\n",
        "    df['AMBIPERC'] = df['AMBI'] / df['LENGTH']\n",
        "    print('Amount of ambiguous nucleotides were added to dataframe in absolute numbers and percentages')\n",
        "    return df\n",
        "\n",
        "\n",
        "def too_much_ambi(dataframe, threshold=0.01):\n",
        "    df = dataframe\n",
        "    df = df[df.AMBIPERC < threshold]\n",
        "    print('Sequences containing more than 1% ambiguous nucleotides were deleted from dataframe')\n",
        "    return df\n",
        "\n",
        "\n",
        "def drop_all_ambi(dataframe):\n",
        "    df = dataframe\n",
        "    df = df[df.AMBIPERC == 0.0]\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0jcmWFxOeOQ"
      },
      "source": [
        "# 2. Length - removing too long or too short ITS\n",
        "Technical standpoint: Neural networks require input having the same size, this is why we e.g. extract some features with kmer (because they all end up having same size). For OHE, we need to padd the sequences up with an ambiguous nucleotide to all have the same length (this could be explained more).\\\n",
        "Biological standpoint: average length of ITS region is 550bp(?), ITS regions much shorter and much longer than that maybe do not hold any biological meaning\\\n",
        "This is why we are checking the distribution of the lengths of ITS, where to cut (min and max) and how much we lose if we cut at min and max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkrdqPmDP28p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def length_stats(filecsv):\n",
        "    df = pd.read_csv(filecsv)\n",
        "    print(f\"Length of shortest sequence: {df['LENGTH'].min()}\")\n",
        "    print(f\"Length of longest sequence: {df['LENGTH'].max()}\")\n",
        "    print(f\"Average length of sequences: {df['LENGTH'].mean():0.2f}\")\n",
        "    upper = df[df.LENGTH <= 700]\n",
        "    lowerupper = upper[upper.LENGTH >= 400]\n",
        "    print(f\"There are {lowerupper.shape[0]} sequences with lengths between 400 and 700.\")\n",
        "    print(f\"This is {lowerupper.shape[0]/df.shape[0]*100:0.2f}% of the original dataset.\")\n",
        "\n",
        "    # Project settings for plots\n",
        "    plt.style.use('bmh')\n",
        "    plt.rcParams['font.family'] = 'serif'\n",
        "    plt.rcParams['font.serif'] = 'UGent Panno Text'\n",
        "    plt.rcParams['font.monospace'] = 'UGent Panno Text'\n",
        "    plt.rcParams['font.size'] = 10\n",
        "    plt.rcParams['axes.labelsize'] = 10\n",
        "    plt.rcParams['axes.labelweight'] = 'bold'\n",
        "    plt.rcParams['axes.titlesize'] = 10\n",
        "    plt.rcParams['xtick.labelsize'] = 8\n",
        "    plt.rcParams['ytick.labelsize'] = 8\n",
        "    plt.rcParams['legend.fontsize'] = 10\n",
        "    plt.rcParams['figure.titlesize'] = 12\n",
        "    # For main: (UGent blue: color='#1E64C8')\n",
        "    # For accents: (UGent yellow: color='#FFD200', linestyle='dashed', linewidth=2)\n",
        "    # Set an aspect ratio\n",
        "    width, height = plt.figaspect(4)\n",
        "    fig = plt.figure(figsize=(width, height), dpi=400)\n",
        "\n",
        "    df.plot.hist(color='#1E64C8', bins=100, align='right')\n",
        "    plt.title(f'Distribution of the lengths of ITS sequences from QIIME release with {filecsv[9:-10]}% similarity threshold')\n",
        "    plt.xlabel('Length of ITS')\n",
        "    plt.xticks(range(0, 1501, 50), rotation='vertical')\n",
        "    plt.axvline(x=400, color='#FFD200', linestyle='dashed', linewidth=2)\n",
        "    plt.gca().get_xticklabels()[8].set_weight('bold')\n",
        "    plt.axvline(x=700, color='#FFD200', linestyle='dashed', linewidth=2)\n",
        "    plt.gca().get_xticklabels()[14].set_weight('bold')\n",
        "    # svg ensures no loss of quality when enlarging\n",
        "    plt.savefig(f'LengthDistribution{filecsv[9:-10]}.svg')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "length_stats('Taxonomy_97_final.csv')\n",
        "length_stats('Taxonomy_99_final.csv')\n",
        "length_stats('Taxonomy_dynamic_final.csv')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![LengthDistribution97](https://user-images.githubusercontent.com/127412115/236632302-41945a7c-6f5d-494f-9110-4c3d61741841.svg)\\\n",
        "Length of shortest sequence: 140\\\n",
        "Length of longest sequence: 1492\\\n",
        "Average length of sequences: 552.11\\\n",
        "There are 49390 sequences with lengths between 400 and 700.\\\n",
        "This is 94.69% of the original dataset.\n",
        "\n",
        "![LengthDistribution99](https://user-images.githubusercontent.com/127412115/236632323-b30fc254-ee90-4248-a2fe-3c6991aa9034.svg)\\\n",
        "Length of shortest sequence: 142\\\n",
        "Length of longest sequence: 1501\\\n",
        "Average length of sequences: 542.38\\\n",
        "There are 99509 sequences with lengths between 400 and 700.\\\n",
        "This is 96.00% of the original dataset.\n",
        "\n",
        "![LengthDistributiondynamic](https://user-images.githubusercontent.com/127412115/236632336-66ec2312-a899-4022-b879-c7fd56e5ea0c.svg)\\\n",
        "Length of shortest sequence: 140\\\n",
        "Length of longest sequence: 1501\\\n",
        "Average length of sequences: 544.77\\\n",
        "There are 80441 sequences with lengths between 400 and 700.\\\n",
        "This is 95.56% of the original dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG549j-mP3P-"
      },
      "source": [
        "# 3. Representation - making the dataset more balanced (- Augmentation?)\n",
        "To make the dataset more balanced:\n",
        "- working with a minimum requirement (e.g. a species needs at least 5 representations of sequences)\n",
        "- working with a maximum requirement (e.g. overrepresented species get randomly deleted some sequences to reduce their abundance)\n",
        "- adding reverse complements to the underrepresented species without changing the overrepresented species\\\n",
        "note: overrepresented=higher than average amount of sequences per species, underrepresented=lower than average amount of sequences per species"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghhlJrLwQ323"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYxbSs69lxP6"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
