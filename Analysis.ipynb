{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reDfqiI58oVq"
      },
      "source": [
        "# 1. Ambiguous nucleotides - removing sequencing errors\n",
        "- check if they are abundant in certain sequences (higher than 1% could be because of sequencing errors => not good to use)\n",
        "- check if there is a big los if we delete sequences with 1 or more ambiguous nucleotides\n",
        "- what if juste delete the ambiguous nucleotides in the sequences themselves but don't delete the entire sequence?\\\n",
        "If we are able to delete these without losing a lot of important data (distribution remains the same for example, not a big loss of indidvidual species), it would simplify the OHE and kmers a lot (because only ATGC instead of ATGCRYSWKMBDHVN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDhktwrROazO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuKL4QxJ8oIZ"
      },
      "outputs": [],
      "source": [
        "def how_many_ambi(dataframe):\n",
        "    df = pd.read_csv(dataframe)\n",
        "    searchfor = ['R', 'Y', 'S', 'W', 'K', 'M', 'B', 'D', 'H', 'V', 'N']\n",
        "    df['AMBI'] = df['SEQ'].str.count('|'.join(searchfor))\n",
        "    df['AMBIPERC'] = df['AMBI'] / df['LENGTH']\n",
        "    print('Amount of ambiguous nucleotides were added to dataframe in absolute numbers and percentages')\n",
        "    return df\n",
        "\n",
        "\n",
        "def too_much_ambi(dataframe, threshold=0.01):\n",
        "    df = dataframe\n",
        "    df = df[df.AMBIPERC < threshold]\n",
        "    print('Sequences containing more than 1% ambiguous nucleotides were deleted from dataframe')\n",
        "    return df\n",
        "\n",
        "\n",
        "def drop_all_ambi(dataframe):\n",
        "    df = dataframe\n",
        "    df = df[df.AMBIPERC == 0.0]\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0jcmWFxOeOQ"
      },
      "source": [
        "# 2. Length - removing too long or too short ITS\n",
        "Technical standpoint: Neural networks require input having the same size, this is why we e.g. extract some features with kmer (because they all end up having same size). For OHE, we need to padd the sequences up with an ambiguous nucleotide to all have the same length (this could be explained more).\\\n",
        "Biological standpoint: average length of ITS region is 550bp(?), ITS regions much shorter and much longer than that maybe do not hold any biological meaning\\\n",
        "This is why we are checking the distribution of the lengths of ITS, where to cut (min and max) and how much we lose if we cut at min and max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkrdqPmDP28p"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv(\"Taxonomy_99_final.csv\")\n",
        "print(f\"Length of shortest sequence: {df['LENGTH'].min()}\")\n",
        "print(f\"Length of longest sequence: {df['LENGTH'].max()}\")\n",
        "print(f\"Average length of sequences: {df['LENGTH'].mean():0.2f}\")\n",
        "upper = df[df.LENGTH <= 650]\n",
        "lowerupper = upper[upper.LENGTH >= 450]\n",
        "print(f\"The amount of sequences between 450 and 650 from the dataset are: {lowerupper.shape[0]}.\")\n",
        "print(f\"This is {lowerupper.shape[0]/df.shape[0]*100:0.2f}% of the original dataset. \")\n",
        "\n",
        "# Project settings for plots\n",
        "plt.style.use('bmh')\n",
        "plt.rcParams['font.family'] = 'serif'\n",
        "plt.rcParams['font.serif'] = 'UGent Panno Text'\n",
        "plt.rcParams['font.monospace'] = 'UGent Panno Text'\n",
        "plt.rcParams['font.size'] = 10\n",
        "plt.rcParams['axes.labelsize'] = 10\n",
        "plt.rcParams['axes.labelweight'] = 'bold'\n",
        "plt.rcParams['axes.titlesize'] = 10\n",
        "plt.rcParams['xtick.labelsize'] = 8\n",
        "plt.rcParams['ytick.labelsize'] = 8\n",
        "plt.rcParams['legend.fontsize'] = 10\n",
        "plt.rcParams['figure.titlesize'] = 12\n",
        "# For main: (UGent blue: color='#1E64C8')\n",
        "# For accents: (UGent yellow: color='#FFD200', linestyle='dashed', linewidth=2)\n",
        "# Set an aspect ratio\n",
        "width, height = plt.figaspect(4)\n",
        "fig = plt.figure(figsize=(width,height), dpi=400)\n",
        "\n",
        "df.plot.hist(color='#1E64C8', bins=94, align='right')\n",
        "plt.title('Distribution of the lengths of ITS sequences')\n",
        "plt.xlabel('Length of ITS')\n",
        "plt.xticks(range(0, 1501, 50), rotation='vertical')\n",
        "plt.axvline(x=450, color='#FFD200', linestyle='dashed', linewidth=2)\n",
        "plt.gca().get_xticklabels()[9].set_weight('bold')\n",
        "plt.axvline(x=650, color='#FFD200', linestyle='dashed', linewidth=2)\n",
        "plt.gca().get_xticklabels()[13].set_weight('bold')\n",
        "# svg ensures\n",
        "plt.savefig('LengthDistribution.svg')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Length of shortest sequence: 142\\\n",
        "Length of longest sequence: 1501\\\n",
        "Average length of sequences: 542.38\\\n",
        "The amount of sequences between 450 and 650 from the dataset are: 90211.\\\n",
        "This is 87.03% of the original dataset.\\\n",
        "\n",
        "Plotting the lengths of the ITS sequences in a histogram gives can be seen in the following figure. Lengths of 450 and 650 were highlighted as they were chosen to be the minimum and maximum.\\\n",
        "![LengthDistribution](https://user-images.githubusercontent.com/127412115/236612727-aa08bb36-477f-42a6-b0ea-2549046ae406.svg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG549j-mP3P-"
      },
      "source": [
        "# 3. Representation - making the dataset more balanced (- Augmentation?)\n",
        "To make the dataset more balanced:\n",
        "- working with a minimum requirement (e.g. a species needs at least 5 representations of sequences)\n",
        "- working with a maximum requirement (e.g. overrepresented species get randomly deleted some sequences to reduce their abundance)\n",
        "- adding reverse complements to the underrepresented species without changing the overrepresented species\\\n",
        "note: overrepresented=higher than average amount of sequences per species, underrepresented=lower than average amount of sequences per species"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghhlJrLwQ323"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYxbSs69lxP6"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
