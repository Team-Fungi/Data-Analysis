{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqbbRQoVCJFv"
      },
      "source": [
        "## 1. Collecting the data\n",
        "QIIME release from UNITE website, following text is copied from the unite website and is a good example of what we could write in the thesis:\n",
        "\n",
        "*Three sets of QIIME files are released, corresponding to the SHs resulting from clustering at the 3% distance (97% similarity) and 1% distance (99% similarity) threshold levels. The third set of files is the result of a dynamic use of clustering thresholds, such that some SHs are delimited at the 3% distance level, some at the 2.5% distance level, some at the 2% distance level, and so on; these choices were made manually by experts of those particular lineages of fungi. The syntax is the same throughout the three sets of files.*\n",
        "\n",
        "*Each SH is given a stable name of the accession number type, here shown in the FASTA file of the dynamic set:*\n",
        "\n",
        "\\>SH099456.05FU_FJ357315_refs \n",
        "CACAATATGAAGGCGGGCTGGCACTCCTTGAGAGGACCGGC…\n",
        "\n",
        "*SH099456 = accession number of the SH 05FU = global key release 5, organism group FUngi FJ357315 = GenBank/UNITE accession number of sequence chosen to represent the SH refs = this is a manually designated RefS (reps = this is an automatically chosen RepS*)\n",
        "\n",
        "*In the corresponding text file, the classification string of the SH is found:*\n",
        "\n",
        "*SH099456.05FU_FJ357315_refs k__Fungi;p__Ascomycota;c__Dothideomycetes;o__Pleosporales;f__Pleosporaceae;g__Embellisia;s__Embellisia_planifunda*\n",
        "\n",
        "*This specifies the hierarchical classification of the sequence. k = kingdom; p = phylum ; c = class ; o = order ; f = family ; g = genus ; and s = species. Missing information is indicated as \"unidentified\" item; “f__unidentified;” means that no family name for the sequence exists.*\n",
        "\n",
        "- something more about which version (most recent one) and why\n",
        "- something about the contents of the download (so 3 sets of QIIME release, all having 1 fasta file and 1 txt file, kind of like the explanation above)\n",
        "- maybe some more explanation about what each file (fasta and txt) file contains, kind of like the explanation above but then in a full text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOo1WHkvsHKS"
      },
      "source": [
        "# Saving the data in csv files\n",
        "- Because we find csv files are easier to handle than the txt + fasta seperately\n",
        "- CSV file are easy to manipulate and visualise with pandas\n",
        "- working with the 3 releases (99%, 97% and dynamic thresholds) because idk honestly, I'm just not sure which one to use yet so I'll convert all of them:) if we end op finding a good reason to choose one or the other, we can still delete them\n",
        "\n",
        "**CSV file contents**\n",
        "\n",
        "Taxonomy_XX.csv is a csv file with all info from the fasta and txt file from QIIME release + length of sequences\n",
        "\n",
        "It has following columns: ['ACCNUM' 'KINGDOM' 'PHYLUM' 'CLASS' 'ORDER' 'FAMILY' 'GENUS' 'SPECIES', 'SEQ' 'LENGTH']\n",
        "\n",
        "Function was made where the following steps were taken (basically what the code below does):\n",
        "1. loading TXT file with pandas read_csv\n",
        "2. Removing prefixes from each column (k__, p__, ...)\n",
        "3. Entries with XX_XX_Incertae_sedis replaced with NaN for easier filtering with pandas as we will delete them anyway (for supervised training, we need data with the right labels)\n",
        "4. Create list of sequences from FASTA file and add them to the dataframe (note: txt has same order as fasta file so we don't need to worry about losing the order later as the order is contained when adding the list to the dataframe)\n",
        "5. Adding column 'SEQ' with sequences to dataframe\n",
        "6. Adding column 'LENGTH' with lengths of sequences: for easy visualisation later on, length can be determined quickly with the BioPython/BioSeq module (maybe some short intermezzo about BioPython can be added here?)\n",
        "7. saving pandas dataframe into csv with save_csv\n",
        "\n",
        "Same steps for each QIIME set!! So 3 times\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXIDlewyr4u9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from Bio import SeqIO\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LexGAST5skjl"
      },
      "outputs": [],
      "source": [
        "def QIIME_to_CSV(filetxt, filefasta):\n",
        "    # Loading Taxonomy data into dataframe, make column names/header\n",
        "    header = ['ACCNUM', 'KINGDOM', 'PHYLUM', 'CLASS', 'ORDER', 'FAMILY', 'GENUS', 'SPECIES']\n",
        "    DataframeAll = pd.read_csv(filetxt,\n",
        "                               delimiter=r'[\\t;]',\n",
        "                               engine='python',\n",
        "                               names=header)\n",
        "\n",
        "    # Removing prefixes from each column (k__, p__, ...)\n",
        "    for column in DataframeAll:\n",
        "        DataframeAll[column] = DataframeAll[column].str.lstrip(f'{str(column)[0].lower()}__')\n",
        "        if str(column) == 'SPECIES':\n",
        "            DataframeAll[column] = DataframeAll[column].str.rstrip('_sp')\n",
        "\n",
        "    # Replacing XX_XX_Incertae_sedis with NaN\n",
        "    for column in DataframeAll:\n",
        "        DataframeAll.loc[DataframeAll[str(column)].str.contains('sedis'), str(column)] = 'NaN'\n",
        "\n",
        "    # Create list of sequences\n",
        "    # Note: Fasta file has same order as txt file\n",
        "    sequences = []\n",
        "    for record in SeqIO.parse(filefasta, 'fasta'):\n",
        "        sequences.append(record.seq)\n",
        "\n",
        "    # Adding column 'SEQ' with sequences to dataframe\n",
        "    # Adding column 'LENGTH' with lengths of sequences\n",
        "    # Note: format of sequences = BioSeq\n",
        "    DataframeAll['SEQ'] = sequences\n",
        "    DataframeAll['LENGTH'] = DataframeAll['SEQ'].str.len()\n",
        "\n",
        "    # Saving csv file for further use\n",
        "    DataframeAll.to_csv(f'Taxonomy_{str(filefasta)[19:-17]}.csv', index=None)\n",
        "    print(f'QIIME set combined to Taxonomy_{str(filefasta)[19:-17]}.csv')\n",
        "\n",
        "\n",
        "QIIME_to_CSV('sh_taxonomy_qiime_ver9_97_29.11.2022.txt', 'sh_refs_qiime_ver9_97_29.11.2022.fasta')\n",
        "QIIME_to_CSV('sh_taxonomy_qiime_ver9_99_29.11.2022.txt', 'sh_refs_qiime_ver9_99_29.11.2022.fasta')\n",
        "QIIME_to_CSV('sh_taxonomy_qiime_ver9_dynamic_29.11.2022.txt', 'sh_refs_qiime_ver9_dynamic_29.11.2022.fasta')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezaRSTClcXsH"
      },
      "source": [
        "# 2. Cleaning the data\n",
        "Cleaning was done following these steps:\n",
        "1. check database for duplicates and delete one of the duplicate duos so no more duplicates in the dataset are present\n",
        "2. Check for rows with NaN in dataset at any of the taxonomic levels and delete these rows (for supervised training, we need data with the right labels)\n",
        "3. give back report/table/overview of cleaning steps\n",
        "4. Save cleaned data into csv for further use (Taxonomy_XX_final.csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qA2qyEscony"
      },
      "outputs": [],
      "source": [
        "def data_cleaning(filecsv):\n",
        "    # Performing the desired cleaning steps\n",
        "    df = pd.read_csv(filecsv)\n",
        "    df_noduplicates = df.drop_duplicates(subset='SEQ')\n",
        "    df_final = df_noduplicates.dropna()\n",
        "    # calculating 'losses' due to cleaning\n",
        "    s_df = len(df.index)\n",
        "    s_dup = len(df.index) - len(df_noduplicates.index)\n",
        "    p_dup = f'{str(s_dup / s_df * 100)[:5]}%'\n",
        "    s_nan = len(df.index) - len(df_final)\n",
        "    p_nan = f'{str(s_nan / s_df * 100)[:5]}%'\n",
        "    s_final = len(df_final.index)\n",
        "    p_final = f'{str(s_final / s_df * 100)[:5]}%'\n",
        "    df_sizes = pd.DataFrame({'Consisting of': [\"QIIME Release\", \"Duplicates\", \"Entries with NaN\", \"Final Dataset\"],\n",
        "                             'Size': [s_df, s_dup, s_nan, s_final],\n",
        "                             '% to start': ['/', p_dup, p_nan, p_final]})\n",
        "    # Saving the cleaned data into csv and printing the 'losses' due to cleaning\n",
        "    df_final.to_csv(f'{filecsv.rstrip(\".csv\")}_final.csv', index=None)\n",
        "    print(f'Data is cleaned and saved in {filecsv[:-4]}_final.csv\\n'\n",
        "          f'Loss of cleaning[NEEDS TO BE CHANGED]:\\n'\n",
        "          f'{df_sizes.to_markdown()}')\n",
        "\n",
        "\n",
        "data_cleaning('Taxonomy_97.csv')\n",
        "data_cleaning('Taxonomy_99.csv')\n",
        "data_cleaning('Taxonomy_dynamic.csv')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DicLWAN2r9mG"
      },
      "source": [
        "Data is cleaned and saved in Taxonomy_97_final.csv\\\n",
        "Loss of cleaning[NEEDS TO BE CHANGED]:\n",
        "\n",
        "|    | Consisting of    |   Size | % to start   |\n",
        "|---:|:-----------------|-------:|:-------------|\n",
        "|  0 | QIIME Release    | 111485 | /            |\n",
        "|  1 | Duplicates       |      0 | 0.0%         |\n",
        "|  2 | Entries with NaN |  59327 | 53.21%       |\n",
        "|  3 | Final Dataset    |  52158 | 46.78%       |\n",
        "\n",
        "Data is cleaned and saved in Taxonomy_99_final.csv\\\n",
        "Loss of cleaning[NEEDS TO BE CHANGED]:\n",
        "\n",
        "|    | Consisting of    |   Size | % to start   |\n",
        "|---:|:-----------------|-------:|:-------------|\n",
        "|  0 | QIIME Release    | 197557 | /            |\n",
        "|  1 | Duplicates       |      2 | 0.001%       |\n",
        "|  2 | Entries with NaN |  93903 | 47.53%       |\n",
        "|  3 | Final Dataset    | 103654 | 52.46%       |\n",
        "\n",
        "Data is cleaned and saved in Taxonomy_dynamic_final.csv\\\n",
        "Loss of cleaning[NEEDS TO BE CHANGED]:\n",
        "\n",
        "|    | Consisting of    |   Size | % to start   |\n",
        "|---:|:-----------------|-------:|:-------------|\n",
        "|  0 | QIIME Release    | 162041 | /            |\n",
        "|  1 | Duplicates       |      1 | 0.000%       |\n",
        "|  2 | Entries with NaN |  77864 | 48.05%       |\n",
        "|  3 | Final Dataset    |  84177 | 51.94%       |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nix1wu7vf68W"
      },
      "source": [
        "# DONE => analysis can start"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
